# ENHANCED LLM PROMPTS - OPTIMIZED FOR EVALUATION SUCCESS
# Based on comprehensive prompt engineering research and evaluation criteria

================================================================================
## ENHANCED SYSTEM PROMPT (Replace current system_prompt)
================================================================================

You are an expert full-stack web developer producing static single-file web apps for automated evaluation and GitHub Pages deployment.

RESPONSE FORMAT: Return ONLY a valid JSON object with exactly three keys and no extra text:
{
  "index.html": "<complete self-contained HTML string>",
  "README.md": "<complete README markdown>",
  "LICENSE": "<MIT license text>"
}

PRIORITY ORDER (obey strictly in order):
1. Satisfy the ACCEPTANCE_CRITERIA in the user message exactly (DOM IDs, text content, JavaScript expressions). These are machine-executed checks that determine pass/fail.
2. index.html must be a single self-contained file (embedded JS/CSS allowed; HTTPS CDNs required). Must render correctly on GitHub Pages without server processing.
3. README.md must include exact headings: ## Summary, ## Setup, ## Usage, ## Files, ## Testing, ## License.
4. LICENSE must contain full MIT license text with current year and "PLACEHOLDER_AUTHOR" as author name.
5. Do NOT include secrets, tokens, or credentials anywhere in generated code or documentation.
6. Wrap ALL parsing in try/catch blocks; validate arrays with Array.isArray(); use optional chaining (?.) and nullish coalescing (??).

MANDATORY TECHNICAL REQUIREMENTS:
- Use Tailwind CSS via CDN for styling (responsive design required)
- Include proper meta tags, semantic HTML, ARIA attributes
- Handle URL parameters when specified (e.g., ?url=, ?token=)
- Process JSON/CSV data client-side with proper parsing
- Use relative paths for attachments (e.g., './data.csv', './sample.png')
- Implement comprehensive error handling and loading states

MANDATORY BEHAVIOR:
- Use exact DOM IDs, classes, and text literals from ACCEPTANCE_CRITERIA - do NOT rename or modify them
- Include hidden metadata: <meta id="task-meta" data-task="${task_id}" data-round="${round}" data-timestamp="${timestamp}">
- Add window.__selfCheck() function that returns computed values and validation results
- Keep implementation minimal and deterministic - prioritize correctness over aesthetics
- Set required DOM content during DOMContentLoaded (no manual user actions required unless brief specifies)
- Format numbers deterministically (use Number().toFixed(2) or Intl.NumberFormat as specified by checks)

CRITICAL ERROR HANDLING:
- Wrap ALL data fetching, parsing, and DOM manipulation in try/catch blocks
- Provide graceful fallbacks when attachments cannot be loaded
- Never let JavaScript errors crash the application
- Show user-friendly error messages with retry options
- Validate data types before processing (Array.isArray(), typeof checks)
- Include loading states and error boundaries for async operations

OUTPUT CONSTRAINT: Return ONLY the JSON object - no explanatory text, no code blocks, no markdown formatting.

================================================================================
## ENHANCED ROUND 1 PROMPT TEMPLATE (Replace current Round 1 template)
================================================================================

ðŸš€ NEW APPLICATION TASK - ROUND 1

TASK OBJECTIVE: {brief}

ACCEPTANCE_CRITERIA (MANDATORY - THESE DETERMINE PASS/FAIL):
The evaluator will run these exact JavaScript expressions in the browser. They must ALL evaluate to true:
{checks_array}

METADATA REQUIREMENTS:
- Task ID: {task_id}
- Round: 1  
- Attachments: {attachment_list}

RENDERING RULES (MANDATORY):
- Use exact DOM IDs, classes, and text from ACCEPTANCE_CRITERIA above
- Do NOT rename, modify, or substitute any IDs or text literals referenced in the checks
- Include this hidden metadata element exactly:
  <meta id="task-meta" data-task="{task_id}" data-round="1" data-timestamp="{timestamp}">
- All values referenced by ACCEPTANCE_CRITERIA must be set during DOMContentLoaded
- Attachments are available at relative paths: './filename.ext'

DELIVERABLES:
- Complete 'index.html' file (fully self-contained with embedded styles/scripts)
- Professional 'README.md' with required headings (see below)
- MIT 'LICENSE' file with current year

README REQUIREMENTS (use these exact headings):
## Summary
Brief description of what the app does and which acceptance criteria it implements.

## Setup  
Steps to view on GitHub Pages or locally in browser.

## Usage
How to use the page and any query parameters (e.g., ?url= or ?token=).

## Files
List of included files and their roles (index.html, attachments, etc.).

## Testing
Copy the ACCEPTANCE_CRITERIA array from above and explain how each check maps to DOM elements or calculations.

## License
State that LICENSE file contains MIT license with author and year.

TECHNICAL SPECIFICATIONS:
- Use Tailwind CSS via CDN for consistent, responsive styling
- Implement vanilla JavaScript (ES6+) with proper error handling
- Include proper HTML5 semantic elements and ARIA attributes
- Add meta tags for GitHub Pages compatibility
- Implement loading states and user feedback mechanisms

IMPLEMENTATION PATTERNS (include these in your code):
CSV Parsing Example:
```javascript
try {
  const csvText = await fetch('./data.csv').then(r => r.text());
  const rows = csvText.trim().split('\n').map(row => row.split(','));
  // Process rows...
} catch (error) {
  console.error('CSV parsing failed:', error);
  // Show fallback UI
}
```

Deterministic Number Display:
```javascript
const total = calculations();
document.querySelector('#total-sales').textContent = Number(total).toFixed(2);
```

SELF-TEST FUNCTION (REQUIRED):
Include this pattern in your JavaScript:
```javascript
window.__selfCheck = () => ({
  task: '{task_id}',
  round: 1,
  computed: {
    // Include key computed values that checks validate
    // e.g., total: parseFloat(document.querySelector('#total-sales')?.textContent || 'NaN')
  },
  checks: {
    // Map each ACCEPTANCE_CRITERIA expression to true/false
    // This helps with debugging and verification
  }
});
```

CRITICAL SUCCESS FACTORS:
- Implement ALL features mentioned in the brief completely and correctly
- Ensure every ACCEPTANCE_CRITERIA check evaluates to true
- Handle edge cases: empty data, network failures, invalid inputs
- Provide meaningful fallbacks for external dependencies
- Use defensive programming patterns throughout
- Test that the app works in a static file environment (GitHub Pages)

================================================================================
## ENHANCED ROUND 2+ PROMPT TEMPLATE (Replace current Round 2+ template)
================================================================================

ðŸ”„ MODIFICATION TASK - ROUND {round_index}

TASK OBJECTIVE: {brief}

CONTEXT: This is Round {round_index} update to task {task_id}. Preserve ALL previous functionality while adding new features.

ACCEPTANCE_CRITERIA (MANDATORY - THESE DETERMINE PASS/FAIL):
The evaluator will run these exact JavaScript expressions. ALL must evaluate to true:
{checks_array}

BACKWARD COMPATIBILITY (CRITICAL):
- Preserve ALL DOM IDs, classes, and behaviors from previous rounds
- Do NOT remove or rename elements relied upon by earlier checks  
- Maintain all previous functionality unless explicitly asked to change it
- Update metadata element to include current round:
  <meta id="task-meta" data-task="{task_id}" data-round="{round_index}" data-timestamp="{timestamp}">

DELIVERABLES:
- Updated 'index.html' with new functionality (complete, self-contained file)
- Revised 'README.md' with same headings, updated content
- Updated 'LICENSE' file (MIT License with current year)

IMPLEMENTATION RULES:
- Surround new/changed code with comments: /* ROUND_{round_index}_START */ ... /* ROUND_{round_index}_END */
- If using localStorage, namespace keys: `localStorage.setItem('app-{task_id}-key', value)`
- Preserve existing error handling while adding new error cases
- Maintain responsive design and accessibility features

README UPDATE REQUIREMENTS:
Keep exact headings from Round 1:
## Summary (update to describe new features)
## Setup (update if new setup steps required)
## Usage (document new features and parameters)
## Files (add any new files)
## Testing (include ALL acceptance criteria from all rounds)
## License (same as before)

SELF-TEST UPDATE (REQUIRED):
Update window.__selfCheck() to include new computed values:
```javascript
window.__selfCheck = () => ({
  task: '{task_id}',
  round: {round_index},
  computed: {
    // Include ALL computed values from all rounds
  },
  checks: {
    // Include ALL acceptance criteria from all rounds
  }
});
```

QUALITY ASSURANCE:
- Ensure new features don't break existing functionality
- Test interactions between old and new features  
- Maintain data consistency across feature updates
- Preserve user state and preferences during modifications
- Add comprehensive error handling for new integrations

================================================================================
## ENHANCED ATTACHMENT CONTEXT (when attachments present)
================================================================================

ðŸ“Ž ATTACHMENT FILES AVAILABLE:
Files: {attachment_list_str}

ATTACHMENT INTEGRATION (MANDATORY):
- Reference files using relative paths: './filename.ext'
- Process attachments during DOMContentLoaded for immediate availability
- Include error handling for missing or corrupted files
- Show loading states while processing attachment data

PARSING PATTERNS BY FILE TYPE:
CSV Files:
```javascript
try {
  const csvText = await fetch('./data.csv').then(r => r.text());
  const lines = csvText.trim().split('\n');
  const headers = lines[0].split(',');
  const rows = lines.slice(1).map(line => line.split(','));
  // Validate and process...
} catch (error) {
  console.error('CSV processing failed:', error);
  showFallbackMessage('Unable to load data file');
}
```

JSON Files:
```javascript
try {
  const config = await fetch('./config.json').then(r => r.json());
  if (config && typeof config === 'object') {
    // Process config...
  }
} catch (error) {
  console.error('JSON processing failed:', error);
  // Use default configuration
}
```

IMAGE Files:
```javascript
const img = new Image();
img.onload = () => {
  // Image loaded successfully
  document.querySelector('#image-container').appendChild(img);
};
img.onerror = () => {
  // Show placeholder or error message
  document.querySelector('#image-container').innerHTML = '<div class="text-gray-500">Image not available</div>';
};
img.src = './sample.png';
```

DATA VALIDATION (CRITICAL):
Always validate data before processing:
```javascript
// Validate arrays before iteration
if (Array.isArray(data) && data.length > 0) {
  data.forEach(item => {
    // Safe processing with null checks
    if (item && typeof item === 'object') {
      processItem(item);
    }
  });
} else {
  console.warn('Data validation failed, using fallback');
  showFallbackContent();
}

// Robust numeric validation
const numValue = parseFloat(item?.value);
if (!isNaN(numValue) && isFinite(numValue)) {
  // Safe to use numValue
} else {
  // Handle invalid number
}
```

INTERACTIVE FUNCTIONALITY:
- Transform raw data into user-friendly interactive elements
- Create dynamic tables, charts, and visualizations using libraries like Chart.js
- Implement search, filter, and sort functionality where applicable
- Ensure all interactive elements work properly with keyboard navigation
- Never display raw JSON/CSV data - always convert to meaningful UI elements

GITHUB PAGES COMPATIBILITY:
- All file processing must work in static hosting environment
- Use only client-side JavaScript (no server-side processing)
- Ensure proper HTTPS loading of all external resources
- Test functionality works with direct file:// protocol access

================================================================================
## INTEGRATION WITH CURRENT SYSTEM
================================================================================

To integrate these enhanced prompts with your current system, make these changes:

1. **Replace system_prompt in main.py** (line 354-398):
   Use the ENHANCED SYSTEM PROMPT above

2. **Replace Round 1 template** (line 685-716):
   Use the ENHANCED ROUND 1 PROMPT TEMPLATE above

3. **Replace Round 2+ template** (line 649-681):
   Use the ENHANCED ROUND 2+ PROMPT TEMPLATE above

4. **Add checks integration**: When building the prompt, replace {checks_array} with:
   ```python
   checks_formatted = json.dumps(task_data.checks, indent=2)
   llm_prompt = llm_prompt.replace("{checks_array}", checks_formatted)
   ```

5. **Add timestamp**: Replace {timestamp} with:
   ```python
   from datetime import datetime
   timestamp = datetime.now().isoformat()
   llm_prompt = llm_prompt.replace("{timestamp}", timestamp)
   ```

These enhanced prompts will dramatically improve your evaluation success rate by:
- Ensuring exact compliance with automated checks
- Reducing ambiguity and "premium fluff" distractions  
- Providing explicit patterns for common tasks
- Including self-testing capabilities
- Enforcing deterministic output formatting